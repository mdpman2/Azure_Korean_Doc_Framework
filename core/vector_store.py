import hashlib
from typing import List, Dict, Any, Optional
from azure.search.documents.indexes.models import (
    SearchIndex,
    SimpleField,
    SearchField,
    SearchFieldDataType,
    VectorSearch,
    HnswAlgorithmConfiguration,
    VectorSearchProfile,
    SemanticConfiguration,
    SemanticPrioritizedFields,
    SemanticField,
    SemanticSearch
)
from ..utils.azure_clients import AzureClientFactory
from ..config import Config
from langchain_openai import AzureOpenAIEmbeddings # Moved here from inside __init__

class VectorStore:
    """
    Azure AI Search ê¸°ë°˜ì˜ ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ í´ë˜ìŠ¤.

    ì¸ë±ìŠ¤ ìƒì„±, ë¬¸ì„œ ë²¡í„°í™”(ì„ë² ë”©), ê²€ìƒ‰ ë° ì¦ë¶„ ì—…ë°ì´íŠ¸ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """

    def __init__(self, index_name: Optional[str] = None):
        """
        VectorStore ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            index_name: ì‚¬ìš©í•  AI Search ì¸ë±ìŠ¤ëª…. ìƒëµ ì‹œ Config.SEARCH_INDEX_NAME ì‚¬ìš©.
        """
        self.index_name = index_name or Config.SEARCH_INDEX_NAME
        self.index_client = AzureClientFactory.get_search_index_client()
        self.search_client = AzureClientFactory.get_search_client(self.index_name)

        # ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (LangChain AzureOpenAIEmbeddings ì‚¬ìš©)
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment=Config.EMBEDDING_DEPLOYMENT,
            openai_api_version=Config.OPENAI_API_VERSION,
            azure_endpoint=Config.OPENAI_ENDPOINT,
            api_key=Config.OPENAI_API_KEY
        )

        # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
        self.create_index_if_not_exists()

        # ì¸ë±ìŠ¤ ì´ˆê¸°í™” ë° í•„ë“œ/ì‹œë§¨í‹± ì„¤ì • ìë™ ë³´ì •
        self._ensure_incremental_fields()

    def create_index_if_not_exists(self, vector_dim: int = 1536) -> None:
        """
        AI Search ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
        ë²¡í„° ê²€ìƒ‰ ë° ì‹œë§¨í‹± ë­í‚¹(Semantic Ranking) ì„¤ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.

        Args:
            vector_dim: ë²¡í„° í•„ë“œì˜ ì°¨ì› ìˆ˜ (ê¸°ë³¸ê°’: 1536 - text-embedding-ada-002 ê¸°ì¤€).
        """
        try:
            self.index_client.get_index(self.index_name)
            print(f"âœ… ì¸ë±ìŠ¤ ì¡´ì¬: '{self.index_name}'")
        except Exception: # Changed from bare except
            print(f"ğŸ› ï¸ ì¸ë±ìŠ¤ ìƒì„± ì¤‘: '{self.index_name}'...")

            fields = [
                SimpleField(name="chunk_id", type=SearchFieldDataType.String, key=True),
                SimpleField(name="parent_id", type=SearchFieldDataType.String, filterable=True, facetable=True),
                SimpleField(name="last_modified", type=SearchFieldDataType.String, filterable=True),
                SimpleField(name="content_hash", type=SearchFieldDataType.String, filterable=True),
                SearchField(name="chunk", type=SearchFieldDataType.String, searchable=True, analyzer_name="ko.microsoft"),
                SearchField(name="title", type=SearchFieldDataType.String, searchable=True),
                SearchField(name="text_vector", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                            searchable=True, vector_search_dimensions=vector_dim, vector_search_profile_name="my-vector-profile"),
            ]

            # ë²¡í„° ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ë° í”„ë¡œí•„ ì„¤ì •
            vector_search = VectorSearch(
                algorithms=[HnswAlgorithmConfiguration(name="my-hnsw")],
                profiles=[VectorSearchProfile(name="my-vector-profile", algorithm_configuration_name="my-hnsw")]
            )

            # ì‹œë§¨í‹± ê²€ìƒ‰ ì„¤ì • (í•œêµ­ì–´ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
            semantic_search = SemanticSearch(
                configurations=[
                    SemanticConfiguration(
                        name="my-semantic-config",
                        prioritized_fields=SemanticPrioritizedFields(
                            title_field=None,
                            content_fields=[SemanticField(field_name="chunk")]
                        )
                    )
                ]
            )

            index = SearchIndex(
                name=self.index_name,
                fields=fields,
                vector_search=vector_search,
                semantic_search=semantic_search
            )
            self.index_client.create_index(index)
            print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: '{self.index_name}'")


    def _ensure_incremental_fields(self) -> None:
        """
        ê¸°ì¡´ ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆì— ì¦ë¶„ ì—…ë°ì´íŠ¸ìš© í•„ë“œ ë° ì‹œë§¨í‹± ê²€ìƒ‰ ì„¤ì •ì´ ì—†ìœ¼ë©´ ë™ì ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        try:
            index = self.index_client.get_index(self.index_name)
            field_names = [f.name for f in index.fields]
            updated = False

            if "last_modified" not in field_names:
                print(f"ğŸ› ï¸ 'last_modified' í•„ë“œ ì¶”ê°€ ì¤‘: {self.index_name}")
                index.fields.append(SimpleField(name="last_modified", type=SearchFieldDataType.String, filterable=True))
                updated = True

            if "content_hash" not in field_names:
                print(f"ğŸ› ï¸ 'content_hash' í•„ë“œ ì¶”ê°€ ì¤‘: {self.index_name}")
                index.fields.append(SimpleField(name="content_hash", type=SearchFieldDataType.String, filterable=True))
                updated = True

            if "parent_id" in field_names:
                # parent_idë¥¼ facetableë¡œ ë³€ê²½ ì‹œë„ (ê¸°ë³¸ì ìœ¼ë¡œ êµì²´ëŠ” ì¸ë±ìŠ¤ ì¬ìƒì„± í•„ìš”í•  ìˆ˜ ìˆìŒ)
                pass

            # ì‹œë§¨í‹± ê²€ìƒ‰ ì„¤ì • í™•ì¸ ë° ì¶”ê°€
            if not index.semantic_search or not any(c.name == "my-semantic-config" for c in index.semantic_search.configurations):
                print(f"ğŸ› ï¸ 'my-semantic-config' ì‹œë§¨í‹± ê²€ìƒ‰ ì„¤ì • ì¶”ê°€ ì¤‘: {self.index_name}")
                index.semantic_search = SemanticSearch(
                    configurations=[
                        SemanticConfiguration(
                            name="my-semantic-config",
                            prioritized_fields=SemanticPrioritizedFields(
                                title_field=None,
                                content_fields=[SemanticField(field_name="chunk")]
                            )
                        )
                    ]
                )
                updated = True

            if updated:
                self.index_client.create_or_update_index(index)
                print("âœ… ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆ ë° ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
        except Exception as e:
            print(f"âš ï¸ ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í™•ì¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}") # Changed error message

    def upload_documents(self, chunks: List[Any]) -> None:
        """
        ë¬¸ì„œ ì²­í¬ë¥¼ ë²¡í„°í™”í•˜ì—¬ AI Searchì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
        ë°°ì¹˜ ì„ë² ë”©ì„ í†µí•´ API í˜¸ì¶œ íšŸìˆ˜ë¥¼ ìµœì í™”í•˜ë©°, ê³ ìœ  ID ìƒì„±ì„ í†µí•´ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.

        Args:
            chunks: ì—…ë¡œë“œí•  LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸.
        """
        if not chunks:
            return

        print(f"ğŸ“¡ {len(chunks)}ê°œ ì²­í¬ ë°°ì¹˜ ì„ë² ë”© ë° ì—…ë¡œë“œ ì¤‘... ì¸ë±ìŠ¤: '{self.index_name}'")

        # 1. ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í•œêº¼ë²ˆì— ì„ë² ë”© (ì„±ëŠ¥ ìµœì í™” í•µì‹¬)
        texts = [chunk.page_content for chunk in chunks]
        vectors = self.embeddings.embed_documents(texts)

        # 2. AI Search ì—…ë¡œë“œìš© ë°ì´í„° êµ¬ì„±
        documents = []
        for i, (chunk, vector) in enumerate(zip(chunks, vectors)):
            # íŒŒì¼ëª…ê³¼ ì¸ë±ìŠ¤ë¥¼ ì¡°í•©í•˜ì—¬ ê³ ìœ  ID ìƒì„± (ì¤‘ë³µ ë°©ì§€)
            parent_id_str = str(chunk.metadata.get("source", "unknown"))
            # Encode parent_id to handle non-ascii chars safely in hash
            parent_hash = hashlib.md5(parent_id_str.encode('utf-8')).hexdigest()[:10]

            documents.append({
                "chunk_id": f"c_{parent_hash}_{i}", # Short unique prefix
                "chunk": chunk.page_content,
                "title": chunk.metadata.get("Header 1", "No Title"),
                "parent_id": parent_id_str,
                "last_modified": str(chunk.metadata.get("last_modified", "")),
                "content_hash": str(chunk.metadata.get("content_hash", "")),
                "text_vector": vector
            })

        # 3. 50ê°œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì—…ë¡œë“œ (ë°°ì¹˜ ì²˜ë¦¬)
        for j in range(0, len(documents), 50):
            batch = documents[j:j+50]
            self.search_client.upload_documents(batch)

        print(f"âœ… {len(documents)}ê°œ ì—…ë¡œë“œ ì™„ë£Œ.")

    def is_file_up_to_date(self, file_name: str, file_mod_time: float, file_hash: Optional[str] = None) -> bool:
        """
        í•´ë‹¹ íŒŒì¼ì´ ì´ë¯¸ ìµœì‹  ìƒíƒœë¡œ ì¸ë±ì‹±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        í•´ì‹œ(ë‚´ìš© ê²€ì‚¬)ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™•ì¸í•˜ê³ , ë³´ì¡°ì ìœ¼ë¡œ ìˆ˜ì • ì‹œê°„ì„ í™•ì¸í•©ë‹ˆë‹¤.

        Args:
            file_name: í™•ì¸ ëŒ€ìƒ íŒŒì¼ëª….
            file_mod_time: íŒŒì¼ì˜ ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„.
            file_hash: íŒŒì¼ì˜ SHA256 í•´ì‹œê°’ (ì˜µì…˜).

        Returns:
            ìµœì‹  ìƒíƒœì´ë©´ True, ì•„ë‹ˆë©´ False.
        """
        try:
            results = self.search_client.search(
                search_text="*",
                filter=f"parent_id eq '{file_name}'",
                select=["last_modified", "content_hash"],
                top=1
            )
            for r in results:
                # 1. íŒŒì¼ ë‚´ìš© í•´ì‹œ ë¹„êµ (ê°€ì¥ ì •í™•í•œ ë°©ë²•)
                if file_hash:
                    stored_hash = r.get("content_hash")
                    if stored_hash == file_hash:
                        print(f"â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: '{file_name}' (ë‚´ìš©ì´ ë™ì¼í•¨)")
                        return True

                # 2. ìˆ˜ì • ì‹œê°„ ë¹„êµ
                stored_time = r.get("last_modified")
                if stored_time and float(stored_time) >= file_mod_time:
                    print(f"â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: '{file_name}' (ë‚ ì§œê°€ ìµœì‹ ì„)")
                    return True
            return False
        except Exception:
            return False

    def delete_documents_by_parent_id(self, parent_id: str) -> None:
        """
        íŠ¹ì • íŒŒì¼(parent_id)ì— ì—°ê´€ëœ ëª¨ë“  ì²­í¬ ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤ (ì—…ë°ì´íŠ¸ ì „ ì²˜ë¦¬ìš©).

        Args:
            parent_id: ì‚­ì œí•  ë¶€ëª¨ ë¬¸ì„œ ID(íŒŒì¼ëª…).
        """
        try:
            results = self.search_client.search(
                search_text="*",
                filter=f"parent_id eq '{parent_id}'",
                select=["chunk_id"]
            )

            ids_to_delete = [{"chunk_id": r["chunk_id"]} for r in results]
            if ids_to_delete:
                print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘: '{parent_id}' ({len(ids_to_delete)}ê°œ ì²­í¬)")
                for i in range(0, len(ids_to_delete), 100):
                    batch = ids_to_delete[i:i+100]
                    self.search_client.delete_documents(batch)
                print("âœ… ì‚­ì œ ì™„ë£Œ.")
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
