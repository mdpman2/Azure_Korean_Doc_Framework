import os
import base64
from io import BytesIO
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
import fitz  # pymupdf
from ..utils.azure_clients import AzureClientFactory
from ..config import Config

class HybridDocumentParser:
    """
    ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹(PDF, PPTX, DOCX)ì„ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” íŒŒì„œ.
    Azure Document Intelligence(Layout Model)ì™€ GPT-4o(Vision)ë¥¼ ê²°í•©í•˜ì—¬ ì‚¬ìš©.
    """

    def __init__(self):
        self.di_client = AzureClientFactory.get_di_client()
        self.aoai_client = AzureClientFactory.get_openai_client()
        self.gpt_model = Config.MODELS.get("gpt-4.1") # Default for vision/parsing

    def _encode_image_base64(self, pil_image: Image.Image) -> str:
        """PIL ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def _describe_image(self, pil_image: Image.Image, image_idx: int, context_hint: str = "") -> str:
        """GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ"""
        print(f"   ğŸ¤– Model Analyzing Figure #{image_idx}...")
        base64_img = self._encode_image_base64(pil_image)

        system_prompt = """ë‹¹ì‹ ì€ í•œê¸€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ ë³´ê³  RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì‹œìŠ¤í…œì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

[ì´ë¯¸ì§€ ìœ í˜•ë³„ ë¶„ì„ ê°€ì´ë“œ]
1. **ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤í¬ë¦°ìƒ·/UI í™”ë©´**:
   - ì–´ë–¤ í”„ë¡œê·¸ë¨/ë©”ë‰´ì¸ì§€ ëª…ì‹œ
   - í´ë¦­í•´ì•¼ í•  ë²„íŠ¼, ë©”ë‰´ ê²½ë¡œ, ì„¤ì •ê°’ì„ ì •í™•íˆ ê¸°ìˆ 
   - ë‹¨ê³„ë³„ ì¡°ì‘ ë°©ë²•ì´ ë³´ì´ë©´ ìˆœì„œëŒ€ë¡œ ì„¤ëª…

2. **í‘œ(Table)**:
   - í–‰/ì—´ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³  ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
   - ë²ˆí˜¸(No.), í•­ëª©ëª…, ì„¤ëª… ë“± ì»¬ëŸ¼ ì •ë³´ ìœ ì§€
   - ì…€ ë³‘í•©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê´€ê³„ ì„¤ëª…

3. **ë‹¤ì´ì–´ê·¸ë¨/ìˆœì„œë„**:
   - í™”ì‚´í‘œ ë°©í–¥, íë¦„ ìˆœì„œ ì„¤ëª…
   - ê° ë‹¨ê³„/ë…¸ë“œì˜ ë‚´ìš© ê¸°ìˆ 

4. **ì°¨íŠ¸/ê·¸ë˜í”„**:
   - ë°ì´í„° ìˆ˜ì¹˜, ì¶”ì„¸, í•µì‹¬ ë©”ì‹œì§€ ì„œìˆ 
   - ë²”ë¡€, ì¶• ë ˆì´ë¸” ì •ë³´ í¬í•¨

[ì¶œë ¥ ê·œì¹™]
- í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ì„œìˆ 
- ê²€ìƒ‰ì— ìœ ìš©í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨
- ë‹¨ìˆœ ì‹œê° ë¬˜ì‚¬ë³´ë‹¤ 'ë¬´ì—‡ì„ í•  ìˆ˜ ìˆëŠ”ì§€', 'ì–´ë–¤ ì •ë³´ì¸ì§€' ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…"""

        user_prompt = "ì´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì¤˜."
        if context_hint:
            user_prompt += f"\n\nì°¸ê³  ë¬¸ë§¥: {context_hint}"

        try:
            response = self.aoai_client.chat.completions.create(
                model=self.gpt_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": [
                        {"type": "text", "text": user_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
                    ]}
                ],
                temperature=0.0,
                max_tokens=1500
            )
            return response.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            if "ResponsibleAIPolicyViolation" in error_msg or "content_filter" in error_msg:
                print(f"   âš ï¸ Image analysis skipped: Content filter violation (Responsible AI Policy).")
                return "[ì´ë¯¸ì§€ ë¶„ì„ ìƒëµ: Azure OpenAI ì½˜í…ì¸  í•„í„°ë§ ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.]"

            print(f"   âŒ Error analyzing image: {e}")
            return "[ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨]"

    def _extract_context_around_offset(self, segments: List[Dict[str, Any]], target_offset: int, window: int = 300) -> str:
        """íŠ¹ì • ì˜¤í”„ì…‹ ì£¼ë³€ì˜ í…ìŠ¤íŠ¸ ë¬¸ë§¥ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        context_parts = []
        for seg in segments:
            seg_offset = seg.get("offset", 0)
            if abs(seg_offset - target_offset) < window and seg.get("type") in ["text", "header"]:
                context_parts.append(seg.get("content", "")[:200])
        return " ".join(context_parts)[:400]

    def _enhance_numbered_content(self, content: str, role: str = None) -> Tuple[str, str]:
        """ë²ˆí˜¸ ëª©ë¡ í˜•ì‹ì„ ê°œì„ í•˜ê³  ìœ í˜•ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        import re

        # "06 ì œëª©" ë˜ëŠ” "06. ì œëª©" í˜•ì‹ ê°ì§€
        numbered_pattern = r'^(\d{2})\.?\s+(.+)$'
        match = re.match(numbered_pattern, content.strip())

        if match:
            num, title = match.groups()
            enhanced_content = f"### {num}. {title}"
            return enhanced_content, "numbered_section"

        return content, "text" if role is None else role

    def _pdf_to_images(self, file_path: str, dpi: int = 200) -> Optional[List[Image.Image]]:
        """PyMuPDFë¥¼ ì‚¬ìš©í•˜ì—¬ PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            doc = fitz.open(file_path)
            images = []
            zoom = dpi / 72  # PDFëŠ” ê¸°ë³¸ 72 DPI
            matrix = fitz.Matrix(zoom, zoom)

            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                pix = page.get_pixmap(matrix=matrix)
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                images.append(img)

            doc.close()
            return images
        except Exception as e:
            print(f"   âš ï¸ PDF Image conversion failed (Visual RAG will be skipped): {e}")
            return None

    def parse(self, file_path: str) -> List[Dict[str, Any]]:
        """
        íŒŒì¼ í˜•ì‹(PDF, PPTX, DOCX)ì— ë”°ë¼ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ìˆ˜í–‰
        ë°˜í™˜ê°’: List[Dict] (êµ¬ì¡°í™”ëœ ë¬¸ì„œ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸)
        """
        file_ext = os.path.splitext(file_path)[1].lower()
        print(f"ğŸš€ Parsing started: {file_path} ({file_ext})")

        # 1. Image ë³€í™˜ (PDFì¸ ê²½ìš°ë§Œ Visual RAGìš©)
        page_images = None
        if file_ext == '.pdf':
            page_images = self._pdf_to_images(file_path, dpi=200)

        # 2. Azure Document Intelligence ì‹¤í–‰
        with open(file_path, "rb") as f:
            poller = self.di_client.begin_analyze_document(
                model_id="prebuilt-layout",
                body=f,
                content_type="application/octet-stream",
                output_content_format="markdown" # Markdown í¬ë§· ì‚¬ìš©
            )
        result = poller.result()

        segments = []

        # 3. Tables ì¶”ì¶œ
        # í…Œì´ë¸”ì˜ ì˜¤í”„ì…‹ ë²”ìœ„ë¥¼ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— í…ìŠ¤íŠ¸ ì¤‘ë³µ ì œê±°ì— ì‚¬ìš©
        table_spans = []
        for table in (result.tables or []):
            # í…Œì´ë¸” ì „ì²´ ìŠ¤íŒ¬ ê³„ì‚° (ìµœì†Œ ì‹œì‘ì  ~ ìµœëŒ€ ëì )
            if not table.spans: continue

            start_offset = min(span.offset for span in table.spans)

            # í…Œì´ë¸” ì»¨í…ì¸  ì¬êµ¬ì„± (Azureê°€ ì œê³µí•˜ëŠ” cells í™œìš©)
            table_content = self._table_to_markdown(table)

            segments.append({
                "type": "table",
                "content": table_content,
                "offset": start_offset,
                "page": table.bounding_regions[0].page_number if table.bounding_regions else 1
            })

            # ìŠ¤íŒ¬ ë²”ìœ„ ì €ì¥
            for span in table.spans:
                table_spans.append((span.offset, span.offset + span.length))

        # 4. Paragraphs (Text & Headers) ì¶”ì¶œ
        for para in (result.paragraphs or []):
            # í…Œì´ë¸” ë‚´ë¶€ì— ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ì œì™¸ (ì¤‘ë³µ ë°©ì§€)
            if self._is_offset_in_ranges(para.spans[0].offset, table_spans):
                continue

            content = para.content
            role = para.role if hasattr(para, 'role') else None

            seg_type = "text"
            if role in ["sectionHeading", "title", "pageHeader"]:
                seg_type = "header"

            # ë²ˆí˜¸ ëª©ë¡ í˜•ì‹ ê°œì„  (06, 07 ë“±)
            enhanced_content, detected_type = self._enhance_numbered_content(content, role)
            if detected_type == "numbered_section":
                seg_type = "header"
                content = enhanced_content

            segments.append({
                "type": seg_type,
                "content": content,
                "role": role, # í—¤ë” ë ˆë²¨ ì¶”ë¡ ì„ ìœ„í•´ ì €ì¥
                "offset": para.spans[0].offset,
                "page": para.bounding_regions[0].page_number if para.bounding_regions else 1
            })

        # 5. Figure(ì´ë¯¸ì§€/ì°¨íŠ¸) ê°ì§€ ë° GPT-4o ì²˜ë¦¬
        if (result.figures or []) and page_images:
            print(f"ğŸ“Š Found {len(result.figures)} figures. Starting vision analysis...")

            for idx, figure in enumerate(result.figures):
                if not figure.bounding_regions: continue

                region = figure.bounding_regions[0]
                page_num = region.page_number - 1

                if page_num >= len(page_images):
                    continue

                page_img = page_images[page_num]
                di_page = result.pages[page_num]

                # ì¢Œí‘œ ë³€í™˜ ë° ì´ë¯¸ì§• í¬ë¡­
                polygon = region.polygon
                if not polygon: continue

                x_coords = []
                y_coords = []

                # polygon í¬ë§· ëŒ€ì‘ (ê°ì²´ ë¦¬ìŠ¤íŠ¸ vs ë‹¨ìˆœ float ë¦¬ìŠ¤íŠ¸)
                if all(hasattr(p, 'x') and hasattr(p, 'y') for p in polygon):
                    x_coords = [p.x for p in polygon]
                    y_coords = [p.y for p in polygon]
                elif len(polygon) >= 2 and isinstance(polygon[0], (int, float)):
                    # [x1, y1, x2, y2, ...] í˜•íƒœì¸ ê²½ìš°
                    x_coords = polygon[0::2]
                    y_coords = polygon[1::2]

                if not x_coords or not y_coords:
                    continue

                if di_page.width == 0 or di_page.height == 0:
                    continue

                scale_x = page_img.width / di_page.width
                scale_y = page_img.height / di_page.height

                left = min(x_coords) * scale_x
                top = min(y_coords) * scale_y
                right = max(x_coords) * scale_x
                bottom = max(y_coords) * scale_y

                try:
                    cropped_img = page_img.crop((left, top, right, bottom))
                    if cropped_img.width < 50 or cropped_img.height < 50:
                        continue

                    # ì´ë¯¸ì§€ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
                    start_offset = figure.spans[0].offset if figure.spans else 0
                    context_hint = self._extract_context_around_offset(segments, start_offset)

                    # ë¬¸ë§¥ íŒíŠ¸ì™€ í•¨ê»˜ ì´ë¯¸ì§€ ë¶„ì„
                    desc_text = self._describe_image(cropped_img, idx + 1, context_hint)

                    # Figure ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    segments.append({
                        "type": "image",
                        "content": f"> **[ì´ë¯¸ì§€/ì°¨íŠ¸ ì„¤ëª… {idx+1}]**\n> {desc_text}",
                        "offset": start_offset,
                        "page": region.page_number
                    })

                except Exception as e:
                    print(f"   âš ï¸ Error cropping/analyzing figure {idx+1}: {e}")

        # 6. ì˜¤í”„ì…‹ ê¸°ì¤€ ì •ë ¬ (ë¬¸ì„œ ìˆœì„œ ë³µì›)
        segments.sort(key=lambda x: x["offset"])

        print(f"âœ… Parsing completed. Extracted {len(segments)} segments.")
        return segments

    def _is_offset_in_ranges(self, offset: int, ranges: List[Tuple[int, int]]) -> bool:
        for start, end in ranges:
            if start <= offset < end:
                return True
        return False

    def _table_to_markdown(self, table: Any) -> str:
        """Azure DI Table ê°ì²´ë¥¼ Markdown í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not table.cells:
            return ""

        # í–‰/ì—´ ê°œìˆ˜ íŒŒì•…
        rows = table.row_count
        cols = table.column_count

        # 2ì°¨ì› ë°°ì—´ ìƒì„±
        grid = [["" for _ in range(cols)] for _ in range(rows)]

        for cell in table.cells:
            # ì…€ ë‚´ìš© (ì¤„ë°”ê¿ˆì€ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ í‘œ ê¹¨ì§ ë°©ì§€)
            content = cell.content.replace('\n', ' ')

            # ë³‘í•©ëœ ì…€ ì²˜ë¦¬ (ë‹¨ìˆœíˆ ì²« ë²ˆì§¸ ì¹¸ì—ë§Œ ë‚´ìš© ì‚½ì…í•˜ê±°ë‚˜, ëª¨ë‘ ì±„ìš¸ ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„  ì²« ì¹¸ë§Œ)
            r_idx = cell.row_index
            c_idx = cell.column_index

            if r_idx < rows and c_idx < cols:
                grid[r_idx][c_idx] = content

        # Markdown ë¬¸ìì—´ ì¡°ë¦½
        md_lines = []

        # í—¤ë” (ì²« ë²ˆì§¸ í–‰)
        header_row = "|" + "|".join(grid[0]) + "|"
        md_lines.append(header_row)

        # êµ¬ë¶„ì„ 
        separator = "|" + "|".join(["---"] * cols) + "|"
        md_lines.append(separator)

        # ë°ì´í„° í–‰
        for i in range(1, rows):
            row_str = "|" + "|".join(grid[i]) + "|"
            md_lines.append(row_str)

        return "\n".join(md_lines)
