from typing import Optional, Dict, Any
from ..config import Config
from ..utils.azure_clients import AzureClientFactory

class MultiModelManager:
    """
    GPT-5.2, GPT-4.1, Claude ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì— ëŒ€í•œ API í˜¸ì¶œì„ í†µí•© ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ëª¨ë¸ í‚¤ì— ë”°ë¼ ì ì ˆí•œ Azure OpenAI ì—”ë“œí¬ì¸íŠ¸ ë° ë°°í¬íŒìœ¼ë¡œ ìš”ì²­ì„ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

    [2026-01 ì—…ë°ì´íŠ¸]
    - GPT-5.2 ê¸°ë³¸ ëª¨ë¸ ì§€ì›
    - Structured Outputs ì§€ì›
    - max_completion_tokens íŒŒë¼ë¯¸í„° ì‚¬ìš© (GPT-5.x)
    - reasoning_effort íŒŒë¼ë¯¸í„° ì§€ì› (ì¶”ë¡  ëª¨ë¸)
    """
    def __init__(self, default_model: Optional[str] = None):
        self.default_model = default_model or Config.DEFAULT_MODEL

    def get_completion(
        self,
        prompt: str,
        model_key: Optional[str] = None,
        system_message: str = "You are a helpful assistant.",
        temperature: float = 0.7,
        max_tokens: int = 4000,
        reasoning_effort: Optional[str] = None,
        response_format: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ìš”ì²­ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            model_key: ì‚¬ìš©í•  ëª¨ë¸ í‚¤ (Config.MODELSì— ì •ì˜)
            system_message: ì‹œìŠ¤í…œ ë©”ì‹œì§€
            temperature: ìƒì„± ì˜¨ë„ (0.0 ~ 1.0)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            reasoning_effort: ì¶”ë¡  ê°•ë„ ('low', 'medium', 'high') - GPT-5.x, o3, o4-mini ì „ìš©
            response_format: Structured Outputsìš© ì‘ë‹µ í˜•ì‹ (ì˜ˆ: {"type": "json_schema", ...})

        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        key = model_key or self.default_model
        model_name = Config.MODELS.get(key)

        # ê³ ì„±ëŠ¥ ëª¨ë¸(Advanced) ì—¬ë¶€ í™•ì¸ (Config.ADVANCED_MODELS ê¸°ì¤€)
        is_advanced = key in getattr(Config, "ADVANCED_MODELS", [])

        # í•´ë‹¹ ê·¸ë£¹(ì¼ë°˜/ê³ ì„±ëŠ¥)ì— ë§ëŠ” ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ íšë“ (ìºì‹œ í™œìš©)
        client = AzureClientFactory.get_openai_client(is_advanced=is_advanced)

        if not model_name:
            print(f"âš ï¸ ëª¨ë¸ í‚¤ '{model_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ '{self.default_model}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            model_name = Config.MODELS.get(self.default_model)
            key = self.default_model

        # GPT-5.x ì—¬ë¶€ í™•ì¸ (max_completion_tokens ì‚¬ìš© ëª¨ë¸)
        # o-ì‹œë¦¬ì¦ˆë„ GPT-5.xì™€ ë™ì¼í•œ API íŒŒë¼ë¯¸í„° ì‚¬ìš©
        is_gpt5_series = key.startswith("gpt-5") or key.startswith("o3") or key.startswith("o4")
        is_reasoning_model = key in Config.REASONING_MODELS

        print(f"ğŸ¤– LLM í˜¸ì¶œ ì¤‘: {key} (ë°°í¬ëª…: {model_name}, ê³ ì„±ëŠ¥: {is_advanced}, GPT-5.x: {is_gpt5_series})")

        try:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° êµ¬ì„±
            completion_params = {
                "model": model_name,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature
            }

            # GPT-5.x/o-ì‹œë¦¬ì¦ˆ: max_completion_tokens ì‚¬ìš©, ê·¸ ì™¸: max_tokens
            if is_gpt5_series:
                completion_params["max_completion_tokens"] = max_tokens
            else:
                completion_params["max_tokens"] = max_tokens

            # Reasoning effort (GPT-5.x, o3, o4-mini ì „ìš©)
            if reasoning_effort and is_reasoning_model:
                completion_params["reasoning_effort"] = reasoning_effort
                print(f"   ğŸ§  Reasoning effort: {reasoning_effort}")

            # Structured Outputs (response_format)
            if response_format:
                completion_params["response_format"] = response_format
                print(f"   ğŸ“‹ Structured Output enabled")

            response = client.chat.completions.create(**completion_params)
            return response.choices[0].message.content

        except Exception as e:
            return f"âŒ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    def get_structured_completion(
        self,
        prompt: str,
        json_schema: Dict[str, Any],
        model_key: Optional[str] = None,
        system_message: str = "You are a helpful assistant that responds in JSON.",
        temperature: float = 0.0
    ) -> str:
        """
        Structured Outputsë¥¼ ì‚¬ìš©í•˜ì—¬ JSON í˜•ì‹ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            json_schema: JSON ìŠ¤í‚¤ë§ˆ ì •ì˜
            model_key: ì‚¬ìš©í•  ëª¨ë¸ í‚¤
            system_message: ì‹œìŠ¤í…œ ë©”ì‹œì§€
            temperature: ìƒì„± ì˜¨ë„

        Returns:
            JSON í˜•ì‹ì˜ ì‘ë‹µ ë¬¸ìì—´
        """
        response_format = {
            "type": "json_schema",
            "json_schema": json_schema
        }

        return self.get_completion(
            prompt=prompt,
            model_key=model_key,
            system_message=system_message,
            temperature=temperature,
            response_format=response_format
        )
